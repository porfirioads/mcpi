{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from time import time\n",
    "import numpy as np\n",
    "import math\n",
    "import numpy.linalg as la\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_U(x):\n",
    "    fx = 100*(np.sqrt(x[0]**2+(x[1]+1)**2)-1)**2 + 90*(np.sqrt(x[0]**2+(x[1]-1)**2)-1)**2 -(20*x[0]+40*x[1])\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primera derivada utilizando la derivada central\n",
    "def gradiente(x,delta):\n",
    "    grad=np.zeros(2)\n",
    "    grad[0]=(F_U([x[0]+delta,x[1]])- F_U([x[0]-delta,x[1]]))/(2*delta)\n",
    "    grad[1]=(F_U([x[0],x[1]+delta])- F_U([x[0],x[1]-delta]))/(2*delta)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segunda derivada utilizando la derivada central\n",
    "def Hs(x,delta):\n",
    "    H=np.zeros([2,2])\n",
    "    H[0,0]= (F_U([x[0]+delta,x[1]])  - 2*F_U(x) + F_U([x[0]-delta,x[1]]) )/ delta**2;\n",
    "    H[1,1]= (F_U([x[0],x[1]+delta])  - 2*F_U(x) + F_U([x[0],x[1]-delta]) )/ delta**2; \n",
    "    H[0,1]= (F_U([x[0]+delta,x[1]+delta]) - F_U([x[0]+delta,x[1]-delta]) - F_U([x[0]-delta,x[1]+delta]) + F_U([x[0]-delta,x[1]-delta]) )/ (4*(delta**2));\n",
    "    H[1,0]=H[0,1]\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3\n",
      "2\n",
      "F_U evaluada en : [-3, 2] 1452.2619\n"
     ]
    }
   ],
   "source": [
    "#Evaluar la función con el punto mínimo y [-3,2]\n",
    "#\n",
    "x=[-3,2]\n",
    "print(x[0])\n",
    "print(x[1])\n",
    "len(x)\n",
    "print(\"F_U evaluada en :\" ,x,\"{:.4f}\".format(F_U(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_U evaluada en : [0.5, 0.12] -9.6547\n"
     ]
    }
   ],
   "source": [
    "#Verificar el valor mínimo de la función\n",
    "x=[0.5000,0.1200]\n",
    "print(\"F_U evaluada en :\" ,x,\"{:.4f}\".format(F_U(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir la función para la sección dorada\n",
    "def GoldenSection(x, search):\n",
    "    a = -5\n",
    "    b = 5\n",
    "    tau = 0.381967\n",
    "    epsilon = 1e-5\n",
    "    alpha1 = a*(1 - tau) + b*tau\n",
    "    alpha2 = a*tau + b*(1 - tau)\n",
    "    falpha1 = F_U(x + alpha1*search)\n",
    "    falpha2 = F_U(x + alpha2*search)\n",
    "    for _ in range(0, 1000):\n",
    "        if falpha1 > falpha2:\n",
    "            a = alpha1\n",
    "            alpha1 = alpha2\n",
    "            falpha1 = falpha2\n",
    "            alpha2 = tau*a + (1 - tau)*b\n",
    "            falpha2 = F_U(x + alpha2*search)\n",
    "        else:\n",
    "            b = alpha2\n",
    "            alpha2  = alpha1\n",
    "            falpha2 = falpha1\n",
    "            alpha1  = tau*b + (1 - tau)*a\n",
    "            falpha1 = F_U(x + alpha1*search)\n",
    "        if abs(F_U(x + alpha1*search) - F_U(x + alpha2*search)) < epsilon:\n",
    "            break\n",
    "    return alpha1, falpha1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descenso más pronunciado\n",
    "def StepestDescent(x,ep1,dx):\n",
    "    \n",
    "    falpha_prev = F_U(x)\n",
    "    print('Initial function value = {0:.3f} '.format(falpha_prev))\n",
    "    print('Iter o.\\t x-vector \\tf(x)\\t Deriv ')\n",
    "    print('------------------------------------------')\n",
    "    for i in range(0, 3000):\n",
    "        grad = gradiente(x,dx)\n",
    "        Si = -grad\n",
    "        \n",
    "        alpha, falpha = GoldenSection(x, Si)\n",
    "        if np.abs(falpha - falpha_prev) < ep1 or la.norm(grad) < ep1:\n",
    "            break\n",
    "        falpha_prev = falpha\n",
    "        x = x + alpha*Si\n",
    "        print('{0}\\t[{1:.3f},{2:.3f}]\\t{3:.3f}\\t{4:.3f}'.format(i,x[0], x[1],falpha,la.norm(grad)))\n",
    "    print('------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método de Newtón\n",
    "def Newton_Multivariate(x,ep1,ep2,dx):\n",
    "    falpha_prev = F_U(x)\n",
    "    print('Initial function value = {0:.2f} '.format(falpha_prev))\n",
    "    print('Iter o.\\t x-vector \\tf(x)\\t\\t Deriv ')\n",
    "    print('---------------------------------------------------')\n",
    "    for i in range(1, 500):\n",
    "        f_prev=F_U(x)\n",
    "        grad =gradiente(x,dx)\n",
    "        hess = Hs(x,dx)\n",
    "        si=np.matmul(-1*la.inv(hess),grad.transpose())\n",
    "        x = x + si.transpose()\n",
    "        x=np.ndarray.flatten(x)\n",
    "        f = F_U(x)\n",
    "        print('{0}\\t[{1:.3f},{2:.3f}]\\t{3:.6f}\\t{4:.6f}'.format(i,x[0], x[1],f_prev,la.norm(grad)))\n",
    "        if abs(f-f_prev)<ep1 or la.norm(grad)<ep1:\n",
    "            break;\n",
    "       \n",
    "    print('---------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método de Newtón Modificado\n",
    "\n",
    "def Newton_Modificado(x,delta,ep1):\n",
    "    fx_prev=F_U(x)\n",
    "    print('Initial function value = {0:.4f} '.format(fx_prev))\n",
    "    print('Iter o.\\t x-vector \\tf(x)\\t\\t Deriv ')\n",
    "    print('---------------------------------------------------')\n",
    "    for i in range(30):\n",
    "        direccion=gradiente(x,delta)\n",
    "        H=Hs(x,delta)\n",
    "        direccion=np.atleast_2d(direccion)\n",
    "        si=np.matmul(-la.inv(H),direccion.transpose())\n",
    "        si = si.transpose()\n",
    "        si=np.ndarray.flatten(si)\n",
    "        alpha,fx_curr = GoldenSection(x, si)\n",
    "        print(alpha)\n",
    "        if abs(fx_curr-fx_prev)<ep1 or la.norm(direccion)<ep1:\n",
    "            break;\n",
    "        x = x +  alpha*si\n",
    "        fx_prev=fx_curr\n",
    "        print('{0}\\t[{1:.3f},{2:.3f}]\\t{3:.4f}\\t{4:.4f}'.format(i,x[0], x[1],fx_prev,la.norm(direccion)))\n",
    "        #print(\"%d\\t %f %f\\t %f \\t%f \\n\" %(j,x[0],x[1],fx_curr,la.norm(dire)))\n",
    "        print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método de Levenberrg-Marquardt\n",
    "def LevenberrgMarquardt(x,delta,ep1):\n",
    "    lam = float(1e3)\n",
    "    fx_prev=F_U(x)\n",
    "    print('Initial function value = {0:.4f} '.format(fx_prev))\n",
    "    print('Iter o.\\t x-vector \\tf(x)\\t\\t Deriv ')\n",
    "    print('---------------------------------------------------')\n",
    "    for i in range(30):\n",
    "        fx_prev=F_U(x)\n",
    "        direccion=gradiente(x,delta)\n",
    "        H=Hs(x,delta)\n",
    "        direccion=np.atleast_2d(direccion)\n",
    "        si=np.matmul(-la.inv(H+lam*np.eye(len(x))),direccion.transpose())\n",
    "        \n",
    "        x = x + si.transpose() \n",
    "        x=np.ndarray.flatten(x)\n",
    "        fx_curr = F_U(x)\n",
    "        if fx_curr < fx_prev:\n",
    "            lam = lam/2\n",
    "        else:\n",
    "            lam = 2*lam\n",
    "\n",
    "        if abs(fx_curr-fx_prev)<ep1 or la.norm(direccion)<ep1:\n",
    "            break;\n",
    "\n",
    "    \n",
    "        print('{0}\\t[{1:.3f},{2:.3f}]\\t{3:.6f}\\t{4:.6f}'.format(i,x[0], x[1],fx_prev,la.norm(direccion)))\n",
    "\n",
    "    print('{0}\\t[{1:.3f},{2:.3f}]\\t{3:.6f}\\t{4:.6f}'.format(i,x[0], x[1],fx_curr,la.norm(direccion)))\n",
    "    print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial function value = 1452.262 \n",
      "Iter o.\t x-vector \tf(x)\t Deriv \n",
      "------------------------------------------\n",
      "0\t[0.095,0.023]\t-2.704\t1006.074\n",
      "1\t[0.170,0.141]\t-5.278\t37.036\n",
      "2\t[0.318,0.048]\t-7.369\t23.451\n",
      "3\t[0.375,0.138]\t-8.773\t26.656\n",
      "4\t[0.448,0.092]\t-9.375\t14.021\n",
      "5\t[0.470,0.127]\t-9.583\t10.071\n",
      "6\t[0.491,0.114]\t-9.639\t4.403\n",
      "7\t[0.497,0.123]\t-9.652\t2.509\n",
      "8\t[0.501,0.120]\t-9.655\t1.050\n",
      "9\t[0.503,0.122]\t-9.656\t0.554\n",
      "10\t[0.504,0.122]\t-9.656\t0.236\n",
      "11\t[0.504,0.122]\t-9.656\t0.125\n",
      "12\t[0.504,0.122]\t-9.656\t0.047\n",
      "13\t[0.504,0.122]\t-9.656\t0.027\n",
      "14\t[0.504,0.122]\t-9.656\t0.016\n",
      "15\t[0.504,0.122]\t-9.656\t0.044\n",
      "16\t[0.504,0.122]\t-9.656\t0.026\n",
      "17\t[0.504,0.122]\t-9.656\t0.016\n",
      "18\t[0.504,0.122]\t-9.656\t0.042\n",
      "19\t[0.504,0.122]\t-9.656\t0.025\n",
      "20\t[0.504,0.122]\t-9.656\t0.015\n",
      "21\t[0.504,0.122]\t-9.656\t0.041\n",
      "22\t[0.504,0.122]\t-9.656\t0.025\n",
      "23\t[0.504,0.122]\t-9.656\t0.015\n",
      "24\t[0.504,0.122]\t-9.656\t0.040\n",
      "25\t[0.504,0.122]\t-9.656\t0.024\n",
      "26\t[0.504,0.122]\t-9.656\t0.014\n",
      "27\t[0.504,0.122]\t-9.656\t0.039\n",
      "28\t[0.504,0.122]\t-9.656\t0.023\n",
      "29\t[0.504,0.122]\t-9.656\t0.014\n",
      "30\t[0.504,0.122]\t-9.656\t0.037\n",
      "31\t[0.504,0.122]\t-9.656\t0.022\n",
      "32\t[0.504,0.122]\t-9.656\t0.013\n",
      "33\t[0.504,0.122]\t-9.656\t0.036\n",
      "34\t[0.504,0.122]\t-9.656\t0.022\n",
      "35\t[0.504,0.122]\t-9.656\t0.013\n",
      "36\t[0.504,0.122]\t-9.656\t0.035\n",
      "37\t[0.504,0.122]\t-9.656\t0.021\n",
      "38\t[0.504,0.122]\t-9.656\t0.013\n",
      "39\t[0.504,0.122]\t-9.656\t0.034\n",
      "40\t[0.504,0.122]\t-9.656\t0.020\n",
      "41\t[0.504,0.122]\t-9.656\t0.012\n",
      "42\t[0.504,0.122]\t-9.656\t0.033\n",
      "43\t[0.504,0.122]\t-9.656\t0.020\n",
      "44\t[0.504,0.122]\t-9.656\t0.012\n",
      "45\t[0.504,0.122]\t-9.656\t0.032\n",
      "46\t[0.504,0.122]\t-9.656\t0.019\n",
      "47\t[0.504,0.122]\t-9.656\t0.011\n",
      "48\t[0.504,0.122]\t-9.656\t0.031\n",
      "49\t[0.504,0.122]\t-9.656\t0.019\n",
      "50\t[0.504,0.122]\t-9.656\t0.011\n",
      "51\t[0.504,0.122]\t-9.656\t0.030\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Llamar al descenso más pronunciado\n",
    "x = [-3,2]\n",
    "eps = 1e-6\n",
    "dx = 1e-3\n",
    "StepestDescent(x,eps,dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial function value = 1452.26 \n",
      "Iter o.\t x-vector \tf(x)\t\t Deriv \n",
      "---------------------------------------------------\n",
      "1\t[-0.754,0.524]\t1452.261884\t1006.073751\n",
      "2\t[-0.362,-0.010]\t44.243734\t116.281440\n",
      "3\t[0.094,0.125]\t8.398370\t50.597488\n",
      "4\t[11.775,0.324]\t-3.920442\t21.420343\n",
      "5\t[1.042,0.093]\t22007.141750\t4076.915933\n",
      "6\t[0.640,0.142]\t14.532812\t102.745178\n",
      "7\t[0.524,0.122]\t-8.478611\t18.199370\n",
      "8\t[0.505,0.122]\t-9.635114\t2.212883\n",
      "9\t[0.504,0.122]\t-9.656214\t0.058979\n",
      "10\t[0.504,0.122]\t-9.656230\t0.000048\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Llamar al método de Newtón\n",
    "n_of_var = 2\n",
    "x = [-3, 2]\n",
    "ep1 = 1e-7\n",
    "ep2 = 1e-7\n",
    "delx = 1e-3\n",
    "Newton_Multivariate(x,ep1,ep2,delx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llamar al método de Newtón Modificado\n",
    "delta=1e-3 \n",
    "ep1=1e-3 \n",
    "x = [-3,2]\n",
    "Newton_Modificado(x,delta,ep1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial function value = 1452.2619 \n",
      "Iter o.\t x-vector \tf(x)\t\t Deriv \n",
      "---------------------------------------------------\n",
      "0\t[-2.384,1.604]\t1452.261884\t1006.073751\n",
      "1\t[-1.680,1.139]\t815.737637\t733.709354\n",
      "2\t[-1.104,0.705]\t325.925171\t429.113162\n",
      "3\t[-0.740,0.327]\t102.058669\t201.554316\n",
      "4\t[-0.444,0.133]\t28.672897\t86.884181\n",
      "5\t[-0.164,0.105]\t8.324226\t34.005458\n",
      "6\t[0.546,0.091]\t1.185754\t20.542003\n",
      "7\t[0.508,0.122]\t-9.390497\t11.361149\n",
      "8\t[0.505,0.122]\t-9.656229\t0.409016\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Llamar al método de Levenberrg-Marquardt\n",
    "delta=1e-3 \n",
    "ep1=1e-3\n",
    "x = [-3,2]\n",
    "\n",
    "\n",
    "LevenberrgMarquardt(x,delta,ep1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
