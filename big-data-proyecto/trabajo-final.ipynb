{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Final de Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porfirio Ángel Díaz Sánchez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisitos del proyecto\n",
    "\n",
    "**Descargar librerías:**\n",
    "\n",
    "https://bit.ly/2NqWD2k\n",
    "\n",
    "**Descomprir archivos en `file:/home/cloudera/`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`commons-csv-1.4.jar` y `spark-csv_2.10-1.5.0.jar`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definición de `SparkContext` y `SQLContext`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# En este caso se encuentran definidos por defecto, si no es así, descomentar el siguiente código.\n",
    "# from pyspark import SparkContext\n",
    "# sc = SparkContext()\n",
    "# from pyspark.sql import SQLContext\n",
    "# sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se comprueba la versión del SparkContext\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lectura del dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = 'file:/home/cloudera/Documents/trabajo-final-big-data/On_Time_On_Time_Performance_2017_8.csv'\n",
    "\n",
    "bd = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(file, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis 1\n",
    "\n",
    "Análisis de las variables relacionadas con la cancelación de vuelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Year', 'int'),\n",
       " ('Quarter', 'int'),\n",
       " ('Month', 'int'),\n",
       " ('DayofMonth', 'int'),\n",
       " ('DayOfWeek', 'int'),\n",
       " ('FlightDate', 'string'),\n",
       " ('UniqueCarrier', 'string'),\n",
       " ('AirlineID', 'int'),\n",
       " ('Carrier', 'string'),\n",
       " ('TailNum', 'string'),\n",
       " ('FlightNum', 'int'),\n",
       " ('OriginAirportID', 'int'),\n",
       " ('OriginAirportSeqID', 'int'),\n",
       " ('OriginCityMarketID', 'int'),\n",
       " ('Origin', 'string'),\n",
       " ('OriginCityName', 'string'),\n",
       " ('OriginState', 'string'),\n",
       " ('OriginStateFips', 'int'),\n",
       " ('OriginStateName', 'string'),\n",
       " ('OriginWac', 'int'),\n",
       " ('DestAirportID', 'int'),\n",
       " ('DestAirportSeqID', 'int'),\n",
       " ('DestCityMarketID', 'int'),\n",
       " ('Dest', 'string'),\n",
       " ('DestCityName', 'string'),\n",
       " ('DestState', 'string'),\n",
       " ('DestStateFips', 'int'),\n",
       " ('DestStateName', 'string'),\n",
       " ('DestWac', 'int'),\n",
       " ('CRSDepTime', 'int'),\n",
       " ('DepTime', 'int'),\n",
       " ('DepDelay', 'double'),\n",
       " ('DepDelayMinutes', 'double'),\n",
       " ('DepDel15', 'double'),\n",
       " ('DepartureDelayGroups', 'int'),\n",
       " ('DepTimeBlk', 'string'),\n",
       " ('TaxiOut', 'double'),\n",
       " ('WheelsOff', 'int'),\n",
       " ('WheelsOn', 'int'),\n",
       " ('TaxiIn', 'double'),\n",
       " ('CRSArrTime', 'int'),\n",
       " ('ArrTime', 'int'),\n",
       " ('ArrDelay', 'double'),\n",
       " ('ArrDelayMinutes', 'double'),\n",
       " ('ArrDel15', 'double'),\n",
       " ('ArrivalDelayGroups', 'int'),\n",
       " ('ArrTimeBlk', 'string'),\n",
       " ('Cancelled', 'double'),\n",
       " ('CancellationCode', 'string'),\n",
       " ('Diverted', 'double'),\n",
       " ('CRSElapsedTime', 'double'),\n",
       " ('ActualElapsedTime', 'double'),\n",
       " ('AirTime', 'double'),\n",
       " ('Flights', 'double'),\n",
       " ('Distance', 'double'),\n",
       " ('DistanceGroup', 'int'),\n",
       " ('CarrierDelay', 'double'),\n",
       " ('WeatherDelay', 'double'),\n",
       " ('NASDelay', 'double'),\n",
       " ('SecurityDelay', 'double'),\n",
       " ('LateAircraftDelay', 'double'),\n",
       " ('FirstDepTime', 'int'),\n",
       " ('TotalAddGTime', 'double'),\n",
       " ('LongestAddGTime', 'double'),\n",
       " ('DivAirportLandings', 'int'),\n",
       " ('DivReachedDest', 'double'),\n",
       " ('DivActualElapsedTime', 'double'),\n",
       " ('DivArrDelay', 'double'),\n",
       " ('DivDistance', 'double'),\n",
       " ('Div1Airport', 'string'),\n",
       " ('Div1AirportID', 'int'),\n",
       " ('Div1AirportSeqID', 'int'),\n",
       " ('Div1WheelsOn', 'int'),\n",
       " ('Div1TotalGTime', 'double'),\n",
       " ('Div1LongestGTime', 'double'),\n",
       " ('Div1WheelsOff', 'int'),\n",
       " ('Div1TailNum', 'string'),\n",
       " ('Div2Airport', 'string'),\n",
       " ('Div2AirportID', 'int'),\n",
       " ('Div2AirportSeqID', 'int'),\n",
       " ('Div2WheelsOn', 'int'),\n",
       " ('Div2TotalGTime', 'double'),\n",
       " ('Div2LongestGTime', 'double'),\n",
       " ('Div2WheelsOff', 'int'),\n",
       " ('Div2TailNum', 'string'),\n",
       " ('Div3Airport', 'string'),\n",
       " ('Div3AirportID', 'string'),\n",
       " ('Div3AirportSeqID', 'string'),\n",
       " ('Div3WheelsOn', 'string'),\n",
       " ('Div3TotalGTime', 'string'),\n",
       " ('Div3LongestGTime', 'string'),\n",
       " ('Div3WheelsOff', 'string'),\n",
       " ('Div3TailNum', 'string'),\n",
       " ('Div4Airport', 'string'),\n",
       " ('Div4AirportID', 'string'),\n",
       " ('Div4AirportSeqID', 'string'),\n",
       " ('Div4WheelsOn', 'string'),\n",
       " ('Div4TotalGTime', 'string'),\n",
       " ('Div4LongestGTime', 'string'),\n",
       " ('Div4WheelsOff', 'string'),\n",
       " ('Div4TailNum', 'string'),\n",
       " ('Div5Airport', 'string'),\n",
       " ('Div5AirportID', 'string'),\n",
       " ('Div5AirportSeqID', 'string'),\n",
       " ('Div5WheelsOn', 'string'),\n",
       " ('Div5TotalGTime', 'string'),\n",
       " ('Div5LongestGTime', 'string'),\n",
       " ('Div5WheelsOff', 'string'),\n",
       " ('Div5TailNum', 'string'),\n",
       " ('', 'string')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene número de registros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1 = bd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elimina vuelos desviados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd = bd.filter(bd.Diverted == 0)\n",
    "p2 = bd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imputa con valor 0 los datos faltantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd = bd.na.fill({\n",
    "        'CarrierDelay':0,\n",
    "        'WeatherDelay':0,\n",
    "        'NASDelay':0,\n",
    "        'SecurityDelay':0,\n",
    "        'LateAircraftDelay':0\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crea la columna 'Tarde'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bd = bd.withColumn('Tarde', (bd.CRSDepTime < 2100) & (bd.CRSDepTime >= 1600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene porcentaje de vuelos cancelados que salieron por la tarde**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vuelos_tarde = bd.filter(bd.Tarde == True)\n",
    "vuelos_tarde_cancelados = vuelos_tarde.filter(vuelos_tarde.Cancelled > 0)\n",
    "num_tarde = vuelos_tarde.count()\n",
    "num_tarde_cancelados = vuelos_tarde_cancelados.count()\n",
    "porcentaje_cancelados_tarde = round((num_tarde_cancelados / num_tarde) * 100, 2)\n",
    "p3 = porcentaje_cancelados_tarde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene distancia promedio de los vuelos cancelados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distancia_promedio = bd.filter(bd.Cancelled > 0).select('Distance').groupBy().mean().first()[0]\n",
    "p4 = distancia_promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene el aeropuerto de origen con mayor tasa de vuelos cancelados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Origin='CRP', Porcentaje=21.95)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum, round, count, desc\n",
    "\n",
    "mas_cancelados = bd \\\n",
    "    .groupBy('Origin') \\\n",
    "    .agg(round(sum('Cancelled') / count('*') * 100, 2).alias('Porcentaje')) \\\n",
    "    .sort(desc('Porcentaje')) \\\n",
    "    .select('Origin', 'Porcentaje') \\\n",
    "    .first()\n",
    "\n",
    "print(mas_cancelados)\n",
    "p5 = mas_cancelados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crea vector de features y renombra la variable respuesta a label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "a1 = VectorAssembler(\n",
    "    inputCols=['DayofMonth', 'DayOfWeek', 'Tarde', 'Distance'],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "bd2 = a1.transform(bd).select(col('Cancelled').cast('double').alias('label'), 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partición en conjuntos de Train y Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(bd2_train, bd2_test) = bd2.randomSplit([0.7, 0.3],seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene número de observaciones de train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p6 = bd2_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo de regresión logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lgr = LogisticRegression(\n",
    "    maxIter=10,\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features\",\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "lgr_model = lgr.fit(bd2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene coeficiente de variable `Tarde`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p7 = lgr_model.coefficients[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene área bajo la curva evaluada en `test`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/pyspark/ml/classification.py:207: UserWarning: weights is deprecated. Use coefficients instead.\n",
      "  warnings.warn(\"weights is deprecated. Use coefficients instead.\")\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator as BCE\n",
    "\n",
    "pred_test = lgr_model.transform(bd2_test)\n",
    "auc_test = BCE(metricName = \"areaUnderROC\", rawPredictionCol = 'probability').evaluate(pred_test)\n",
    "p8 = auc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo de bosque aleatorio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol = 'label', outputCol = 'indexed')\n",
    "sI = stringIndexer.fit(bd2_train)\n",
    "bd2_train = sI.transform(bd2_train)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol=\"indexed\",\n",
    "    featuresCol=\"features\",\n",
    "    numTrees=500,\n",
    "    maxDepth=3,\n",
    "    seed = 123,\n",
    "    featureSubsetStrategy=\"sqrt\",\n",
    "    impurity='gini'\n",
    ")\n",
    "\n",
    "rf_model = rf.fit(bd2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene área bajo la curva evaluada en `test`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator as BCE\n",
    "\n",
    "pred_test = rf_model.transform(bd2_test)\n",
    "auc_test = BCE(metricName = \"areaUnderROC\", rawPredictionCol = 'probability').evaluate(pred_test)\n",
    "p9 = auc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Red neuronal de clasificación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(\n",
    "    labelCol=\"label\",\n",
    "    featuresCol=\"features\",\n",
    "    maxIter=100,\n",
    "    layers=[4, 5, 2],\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "mlp_model = rf.fit(bd2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene valor de índice precision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator as MCCE\n",
    "\n",
    "pred_test = mlp_model.transform(bd2_test)\n",
    "precision_test = MCCE(metricName=\"precision\").evaluate(pred_test)\n",
    "p10 = precision_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ¿Cuántas observaciones tiene la base de datos?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510451\n"
     ]
    }
   ],
   "source": [
    "print(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Tras eliminar los vuelos desviados (Diverted==1), ¿cuántas observaciones quedan?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509165\n"
     ]
    }
   ],
   "source": [
    "print(p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. ¿Qué porcentaje de vuelos que han salido por la tarde han sido cancelados?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.53\n"
     ]
    }
   ],
   "source": [
    "print(p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. ¿Cuál es la distancia promedio de los vuelos cancelados?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749.8705689874569\n"
     ]
    }
   ],
   "source": [
    "print(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Cuál es el aeropuerto de origen con mayor tasa de vuelos cancelados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Origin='CRP', Porcentaje=21.95)\n"
     ]
    }
   ],
   "source": [
    "print(p5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Tras dividir la base de datos en los conjuntos de train (70%) y test (30%), ¿Cuántas observaciones tiene el conjunto de train?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356382\n"
     ]
    }
   ],
   "source": [
    "print(p6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Tras ejecutar el modelo de regresión logística para predecir la variable `Cancelled` empleando las variables `DayOfMonth`, `DayOfweek`, `Tarde`, `Distance`, ¿Cuál es el coeficiente de la variable `Tarde`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0432159308007\n"
     ]
    }
   ],
   "source": [
    "print(p7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Bajo el anterior modelo, ¿Cuál es el área bajo la curva evaluada en la base de datos `test`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6511192770431581\n"
     ]
    }
   ],
   "source": [
    "print(p8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Tras ejecutar un bosque aleatorio en el contexto anterior, considerando las mismas variables, ¿Cuánto vale el área bajo la curva evaluada en la base de datos `test`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7847305688776101\n"
     ]
    }
   ],
   "source": [
    "print(p9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Tras ejecutar una red neuronal en el contexto anterior (MultilayerPerceptronClassifier), ¿Cuánto vale el índice precision?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9780276601454351\n"
     ]
    }
   ],
   "source": [
    "print(p10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lee nuevamente el dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = 'file:/home/cloudera/Documents/trabajo-final-big-data/On_Time_On_Time_Performance_2017_8.csv'\n",
    "\n",
    "bd = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(file, inferSchema=True)\n",
    "\n",
    "bd = bd.na.fill({\n",
    "        'CarrierDelay':0,\n",
    "        'WeatherDelay':0,\n",
    "        'NASDelay':0,\n",
    "        'SecurityDelay':0,\n",
    "        'LateAircraftDelay':0\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Elimina los datos correspondientes a vuelos cancelados y desviados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd = bd.filter((bd.Cancelled == 0) & (bd.Diverted == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene número de observaciones tras eliminar cancelados y desviados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p11 = bd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define variable `Retraso2`, que consiste en restarle al retraso total el retraso en la salida**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bd = bd.withColumn('Retraso2', (bd.ArrDelay - bd.LateAircraftDelay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcula promedio de variable `Retraso2`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "promedio = bd.select(avg(col('Retraso2'))).first()[0]\n",
    "p12 = promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene aeropuerto de origen con mayor promedio en variable `Retraso2`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "mas_retraso2 = bd \\\n",
    "    .groupBy('Origin') \\\n",
    "    .agg(avg(col('Retraso2')).alias('PromedioRetraso')) \\\n",
    "    .sort(desc('PromedioRetraso')) \\\n",
    "    .select('Origin', 'PromedioRetraso') \\\n",
    "    .first()\n",
    "\n",
    "p13 = mas_retraso2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcula correlación entre `DepDelay` y `Retraso2`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlacion = bd.stat.corr('DepDelay', 'Retraso2')\n",
    "p14 = correlacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vuelve a definir la variable `Tarde`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bd = bd.withColumn('Tarde', (bd.CRSDepTime < 2100) & (bd.CRSDepTime >= 1600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crea vector de features con las columnas `DepDelay`, `DayOfWeek`, `Tarde` y `Distance`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "a1 = VectorAssembler(\n",
    "    inputCols=['DepDelay', 'DayOfWeek', 'Tarde', 'Distance'],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "bd3 = a1.transform(bd).select(col('Retraso2').cast('double').alias('label'), 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Particiona base de datos en conjuntos `Train` y `Test`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(bd3_train, bd3_test) = bd3.randomSplit([0.7, 0.3],seed=456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene número de registros en `train`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p15 = bd3_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo de regresión lineal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(labelCol=\"label\", featuresCol=\"features\",)\n",
    "\n",
    "lr_model = lr.fit(bd3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene los coeficientes para variable `Tarde`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p16 = lr_model.coefficients[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene índice R2 para base de `train`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "pred_train = lr_model.transform(bd3_train)\n",
    "p17 = RegressionEvaluator(metricName=\"r2\").evaluate(pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene índice R2 para base de `test`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "pred_test = lr_model.transform(bd3_test)\n",
    "p18 = RegressionEvaluator(metricName=\"r2\").evaluate(pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Árbol de regresión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor as DTR\n",
    "\n",
    "dtr = DTR(maxDepth=10)\n",
    "\n",
    "dtr_model = dtr.fit(bd3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene índice R2 para base de `train`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "pred_train = dtr_model.transform(bd3_train)\n",
    "p19 = RegressionEvaluator(metricName=\"r2\").evaluate(pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtiene índice R2 para base de `train`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "pred_test = dtr_model.transform(bd3_test)\n",
    "p20 = RegressionEvaluator(metricName=\"r2\").evaluate(pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Tras eliminar los vuelos cancelados y desviados, ¿Cuántas observaciones contiene la base de datos actual?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498163\n"
     ]
    }
   ],
   "source": [
    "print(p11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. Tras generar la variable `Retraso2 = ArrDelay - LateAircraftDelay`, ¿Cuál es su promedio en el conjunto de datos actuales?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2535997253910869\n"
     ]
    }
   ],
   "source": [
    "print(p12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. ¿Cuál es el aeropuerto de origen con mayor promedio para la variable `Retraso2`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Origin='RDD', PromedioRetraso=35.8876404494382)\n"
     ]
    }
   ],
   "source": [
    "print(p13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14. ¿Cuánto vale la correlación entre `DepDelay` y `Retraso2`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7985696098228822\n"
     ]
    }
   ],
   "source": [
    "print(p14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15. Configurando unas nuevas bases de datos de `train` (70%) y `test` (30%), con la semilla 456, ¿Cuántos casos contiene la base de datos de `train`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348841\n"
     ]
    }
   ],
   "source": [
    "print(p15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. Tras construir el modelo de regresión lineal con las variables `DepDelay`, `Distance`, `DayOfWeek`, `Tarde`, para explicar la variable `Retraso2`, ¿Cuánto vale el coeficiente del modelo para `Tarde`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.56672339152\n"
     ]
    }
   ],
   "source": [
    "print(p16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17. ¿Cuánto vale el índice R2 empleando los datos de la base de `train`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6389857542184951\n"
     ]
    }
   ],
   "source": [
    "print(p17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**18. ¿Cuánto vale el índice R2 empleando los datos de la base de `test`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639342954097753\n"
     ]
    }
   ],
   "source": [
    "print(p18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**19. Considera un árbol de regresión en el contexto anterior con todos los parámetros por defecto y una profundidad de 10. ¿Cuánto vale el índice de ajuste R2 empleando la base de datos de `train`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3924315682261269\n"
     ]
    }
   ],
   "source": [
    "print(p19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20. Considerando el árbol anterior, ¿Cuánto vale el índice de ajuste R2 para la base de datos `test`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3430251883501948\n"
     ]
    }
   ],
   "source": [
    "print(p20)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
